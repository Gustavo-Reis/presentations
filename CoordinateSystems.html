<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">

		<title>Coordinate Systems</title>

		<meta name="description" content="Computer Graphics - Textures">
		<meta name="author" content="Gustavo Reis">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/obsidian.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
		<style type="text/css">
			.output{
				font-size:larger;
				background-color:black;
				color:lightgrey;
			}
		</style>

	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<img src="images/OpenGL/Opengl-logo.svg" width="100%" class="plain">
					<p><center><small>Source:</small></center></p>
					<p><center><small><a href="http://learnopengl.com">Learn OpenGL</a></small></center></p>
					<p><center><small><a href="http://open.gl">Open.GL</a></small></center></p>
				</section>
				<section>				
					<section>
						<h1>Coordinate Systems</h1>
					</section>
					<section>
						<p class="fragment">OpenGL expects all the vertices, that we want to become visible, to be in normalized device coordinates after each vertex shader run.</p>
						<p class="fragment">That is, the x, y and z coordinates of each vertex should be between -1.0 and 1.0: <b>coordinates outside this range will not be visible</b>.</p>
						<p class="fragment">What we usually do, is specify the coordinates in a range we configure ourselves and in the vertex shader transform these coordinates to NDC.</p>
						<p class="fragment">These NDC coordinates are then given to the rasterizer to transform them to 2D coordinates/pixels on your screen.</p>
					</section>
					<section>
						<p class="fragment">Transforming coordinates to NDC and then to screen coordinates is usually accomplished in a step-by-step fashion where we transform an object's vertices to several coordinate systems before finally transforming them to screen coordinates.</p>
						<p class="fragment">The advantage of transforming them to several intermediate coordinate systems is that some operations/calculations are easier in certain coordinate systems as will soon become apparent.</p>
						<div class="fragment"><img src="https://open.gl/media/img/c4_transformation.png" class="plain" width="100%"></div>
					</section>
					<section>
						<p class="fragment">There are a total of 5 different coordinate systems that are of importance to us:</p>
						<ul>
							<li class="fragment">Local space (or Object space)</li>
							<li class="fragment">World space</li>
							<li class="fragment">View space (or Eye space)</li>
							<li class="fragment">Clip space</li>
							<li class="fragment">Screen space</li>
						</ul>
					</section>
				</section>
				<section>
					<section>
						<h2>The Global Picture</h2>
					</section>
					<section>
						<p class="fragment">To transform the coordinates in one space to the next coordinate space we'll use several transformation matrices of which the most important are the <b>model</b>, <b>view</b> and <b>projection</b> matrix.</p>
						<p class="fragment">Our vertex coordinates first start in <b>local space</b> as <b>local coordinates</b> and are then further processed to <b>world coordinates</b>, <b>view coordinates</b>, <b>clip coordinates</b> and eventually end up as <b>screen coordinates</b>.</p>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/coordinate_systems.png" class="plain" width="65%">
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/coordinate_systems.png" class="plain" width="65%">
						<p>1. <b>Local coordinates</b> are the coordinates of your object relative to its local origin: they're the coordinates your object begins in.</p>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/coordinate_systems.png" class="plain" width="65%">
						<p>2. The next step is to transform the local coordinates to world-space coordinates which are coordinates in respect of a larger world. These coordinates are relative to a global origin of the world, together with many other objects also placed relative to the world's origin.</p>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/coordinate_systems.png" class="plain" width="65%">
						<p>3. Next we transform the world coordinates to view-space coordinates in such a way that each coordinate is as seen from the camera or viewer's point of view.</p>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/coordinate_systems.png" class="plain" width="65%">
						<p>4. After the coordinates are in view space we want to project them to clip coordinates. Clip coordinates are processed to the -1.0 and 1.0 range and determine which vertices will end up on the screen.</p>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/coordinate_systems.png" class="plain" width="60%">
						<p>5. And lastly we transform the clip coordinates to screen coordinates in a process we call viewport transform that transforms the coordinates from -1.0 and 1.0 to the coordinate range defined by <code>glViewport</code>. The resulting coordinates are then sent to the rasterizer to turn them into fragments.</p>
					</section>
					<section>
						<p class="fragment">You probably got a slight idea what each individual space is used for.</p>
						<p class="fragment">The reason we're transforming our vertices into all these different spaces is that some operations make more sense or are easier to use in certain coordinate systems.</p>
						<p class="fragment">For example, when modifying your object it makes most sense to do this in local space, while calculating certain operations on the object with respect to the position of other objects makes most sense in world coordinates and so on.</p>
						<p class="fragment">If we want, we could define one transformation matrix that goes from local space to clip space all in one go, but that leaves us with less flexibility.</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Local Space</h2>
					</section>
					<section>
						<p class="fragment">Local space is the coordinate space that is local to your object, i.e. where your object begins in.</p>
						<p class="fragment">Imagine that you've created your cube in a modeling software package (like Maya or Blender).</p>
						<p class="fragment">The origin of your cube is probably at (0,0,0) even though your cube might end up at a different location in your final application.</p>
						<p class="fragment">Probably all the models you've created all have (0,0,0) as their initial position.</p>
						<p class="fragment">All the vertices of your model are therefore in local space: they are all local to your object.</p>
					</section>
				</section>
				<section>
					<section>
						<h2>World Space</h2>
					</section>
					<section>
						<p class="fragment">If we would import all our objects directly in the application they would probably all be somewhere stacked on each other around the world's origin of (0,0,0) which is not what we want.</p>
						<p class="fragment">We want to define a position for each object to position them inside a larger world.</p>
						<p class="fragment">The coordinates in world space are exactly what they sound like: the coordinates of all your vertices relative to a (game) world.</p>
					</section>
					<section>
						<p class="fragment">This is the coordinate space where you want your objects transformed to in such a way that they're all scattered around the place (preferably in a realistic fashion).</p>
						<p class="fragment">The coordinates of your object are transformed from local to world space; this is accomplished with the model matrix.</p>
						<p class="fragment">The model matrix is a transformation matrix that translates, scales and/or rotates your object to place it in the world at a location/orientation they belong to.</p>
					</section>
				</section>
				<section>
					<section>
						<h2>View Space</h2>
					</section>
					<section>
						<p class="fragment">The view space is what people usually refer to as the camera of OpenGL (it is sometimes also known as the camera space or eye space).</p>
						<p class="fragment">The view space is the result of transforming your world-space coordinates to coordinates that are in front of the user's view.</p>
						<p class="fragment">The view space is thus the space as seen from the camera's point of view.</p>
						<p class="fragment">This is usually accomplished with a combination of translations and rotations to translate/rotate the scene so that certain items are transformed to the front of the camera.</p>
						<p class="fragment">These combined transformations are generally stored inside a view matrix that transforms world coordinates to view space.</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Clip Space</h2>
					</section>
					<section>
						<p class="fragment">At the end of each vertex shader run, OpenGL expects the coordinates to be within a specific range and any coordinate that falls outside this range is clipped.</p>
						<p class="fragment">Coordinates that are clipped are discarded, so the remaining coordinates will end up as fragments visible on your screen.</p>
						<p class="fragment">This is also where clip space gets its name from.</p>
						<p class="fragment">Because specifying all the visible coordinates to be within the range -1.0 and 1.0 isn't really intuitive, we specify our own coordinate set to work in and convert those back to NDC as OpenGL expects them.</p>
					</section>
					<section>
						<p class="fragment">To transform vertex coordinates from view to clip-space we define a so called projection matrix that specifies a range of coordinates e.g. -1000 and 1000 in each dimension.</p>
						<p class="fragment">The projection matrix then transforms coordinates within this specified range to normalized device coordinates (-1.0, 1.0).</p>
						<p class="fragment">All coordinates outside this range will not be mapped between -1.0 and 1.0 and therefore be clipped.</p>
					</section>
					<section>
						<p class="fragment">With this range we specified in the projection matrix, a coordinate of (1250, 500, 750) would not be visible, since the x coordinate is out of range and thus gets converted to a coordinate higher than 1.0 in NDC and is therefore clipped.</p>
						<note class="fragment" style="text-align: left"><b>Note</b>: if only a part of a primitive e.g. a triangle is outside the clipping volume OpenGL will reconstruct the triangle as one or more triangles to fit inside the clipping range.</note>
					</section>
					<section>
						<p class="fragment">This viewing box a projection matrix creates is called a frustum and each coordinate that ends up inside this frustum will end up on the user's screen.</p>
						<p class="fragment">The total process to convert coordinates within a specified range to NDC that can easily be mapped to 2D view-space coordinates is called projection since the projection matrix projects 3D coordinates to the easy-to-map-to-2D normalized device coordinates.</p>
					</section>
					<section>
						<p class="fragment">Once all the vertices are transformed to clip space a final operation called perspective division is performed where we divide the x, y and z components of the position vectors by the vector's homogeneous w component; perspective division is what transforms the 4D clip space coordinates to 3D normalized device coordinates.</p>
						<p class="fragment">This step is performed automatically <b>at the end of each vertex shader run</b>.</p>
					</section>
					<section>
						<p class="fragment">It is after this stage where the resulting coordinates are mapped to screen coordinates (using the settings of <code>glViewport</code>) and turned into fragments.</p>
						<p class="fragment">The projection matrix to transform view coordinates to clip coordinates can take two different forms, where each form defines its own unique frustum.</p>
						<p class="fragment">We can either create an <b>orthographic projection</b> matrix or a <b>perspective projection</b> matrix.</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Orthographic Projection</h2>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/orthographic_frustum.png" class="plain" width="60%">
					</section>
					<section>
						<p class="fragment">An orthographic projection matrix defines a cube-like frustum box that defines the clipping space where each vertex outside this box is clipped.</p>
						<p class="fragment">When creating an orthographic projection matrix we specify the width, height and length of the visible frustum.</p>
						<p class="fragment">All the coordinates that end up inside this frustum after transforming them to clip space with the orthographic projection matrix won't be clipped.</p>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/orthographic_frustum.png" class="plain" width="60%">
					</section>
					<section>
						<p class="fragment">The frustum defines the visible coordinates and is specified by a width, a height and a near and far plane.</p>
						<p class="fragment">Any coordinate in front of the near plane is clipped and the same applies to coordinates behind the far plane.</p>
						<p class="fragment">The orthographic frustum directly maps all coordinates inside the frustum to normalized device coordinates since the <b>w</b> component of each vector is untouched; if the <b>w</b> component is equal to <b>1.0</b> perspective division doesn't change the coordinates.</p>
					</section>
					<section>
						<p class="fragment">To create an orthographic projection matrix we make use of GLM's built-in function <code>glm::ortho</code>:</p>
						<pre class="fragment"><code>glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f);</code></pre>
						<p class="fragment">The first two parameters specify the left and right coordinate of the frustum and the third and fourth parameter specify the bottom and top part of the frustum.</p>
						<p class="fragment">With those 4 points we've defined the size of the near and far planes and the 5th and 6th parameter then define the distances between the near and far plane.</p>
						<p class="fragment">This specific projection matrix transforms all coordinates between these x, y and z range values to normalized device coordinates.</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Perspective Projection</h2>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/perspective.png" class="plain" width="50%">
					</section>
					<section>
						<p class="fragment">If you ever were to enjoy the graphics the real life has to offer you'll notice that objects that are farther away appear much smaller.</p>
						<p class="fragment">This weird effect is something we call perspective. Perspective is especially noticeable when looking down the end of an infinite motorway or railway as seen in the following image:</p>
						<div class="fragment"><img src="https://learnopengl.com/img/getting-started/perspective.png" class="plain" width="20%"></div>
					</section>
					<section>
						<p class="fragment">Due to perspective, the lines seem to coincide the farther they're away.</p>
						<p class="fragment">This is exactly the effect perspective projection tries to mimic and it does so using a perspective projection matrix.</p>
						<p class="fragment">The projection matrix maps a given frustum range to clip space, but also manipulates the w value of each vertex coordinate in such a way that the further away a vertex coordinate is from the viewer, the higher this w component becomes.</p>
					</section>
					<section>
						<p class="fragment">Once the coordinates are transformed to clip space they are in the range -w to w (anything outside this range is clipped).</p>
						<p class="fragment">OpenGL requires that the visible coordinates fall between the range -1.0 and 1.0 as the final vertex shader output, thus once the coordinates are in clip space, perspective division is applied to the clip space coordinates:</p>
						<div class="fragment">$$out = \left( \begin{array} \\ \frac{x}{w} \\ \frac{y}{w} \\ \frac{z}{w} \end{array} \right)$$</div>
					</section>
					<section>
						<p class="fragment">Each component of the vertex coordinate is divided by its w component giving smaller vertex coordinates the further away a vertex is from the viewer.</p>
						<p class="fragment">This is another reason why the w component is important, since it helps us with perspective projection.</p>
						<p class="fragment">The resulting coordinates are then in normalized device space.</p>
					</section>
					<section>
						<p class="fragment">A perspective projection matrix can be created in GLM as follows:</p>
						<pre class="fragment"><code>glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width / (float)height, 0.1f, 100.0f);</code></pre>
						<p class="fragment">What <code>glm::perspective</code> does is again create a large frustum that defines the visible space, anything outside the frustum will not end up in the clip space volume and will thus become clipped.</p>
					</section>
					<section>
						<p class="fragment">A perspective frustum can be visualized as a non-uniformly shaped box from where each coordinate inside this box will be mapped to a point in clip space.</p>
						<p class="fragment">An image of a perspective frustum is seen below:</p>
						<div class="fragment"><img src="https://learnopengl.com/img/getting-started/perspective_frustum.png" class="plain" width="40%"></div>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/perspective_frustum.png" class="plain" width="60%">
					</section>
					<section>
						<pre><code>glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width / (float)height, 0.1f, 100.0f);</code></pre>
						<p class="fragment">Its first parameter defines the <b>fov</b> value, that stands for <b>field of view</b> and sets how large the viewspace is.</p>
						<p class="fragment">For a realistic view it is usually set to 45 degrees, but for more doom-style results you could set it to a higher value.</p>
						<p class="fragment">The second parameter sets the aspect ratio which is calculated by dividing the viewport's width by its height.</p>
						<p class="fragment">The third and fourth parameter set the near and far plane of the frustum.</p>
						<p class="fragment">We usually set the near distance to <code>0.1f</code> and the far distance to <code>100.0f</code>.</p>
						<p class="fragment">All the vertices between the near and far plane and inside the frustum will be rendered.</p>
					</section>
					<section>
						<p class="fragment">When using orthographic projection, each of the vertex coordinates are directly mapped to clip space without any fancy perspective division (it still does perspective division, but the w component is not manipulated (it stays 1) and thus has no effect).</p>
						<p class="fragment">Because the orthographic projection doesn't use perspective projection, objects farther away do not seem smaller, which produces a weird visual output.</p>
					</section>
					<section>
						<p class="fragment">For this reason the orthographic projection is mainly used for 2D renderings and for some architectural or engineering applications where we'd rather not have vertices distorted by perspective.</p>
						<p class="fragment">Applications like Blender that are used for 3D modelling sometimes use orthographic projection for modelling, because it more accurately depicts each object's dimensions.</p>
					</section>
					<section>
						<img src="https://learnopengl.com/img/getting-started/perspective_orthographic.png" class="plain" width="70%">
					</section>
				</section>
				<section>
					<section>
						<h2>Putting all Together</h2>
					</section>
					<section>
						<p class="fragment">We create a transformation matrix for each of the aforementioned steps: model, view and projection matrix. </p>
						<p class="fragment">A vertex coordinate is then transformed to clip coordinates as follows:</p>
						<div class="fragment">$$ V_{clip} = M_{projection} \cdot M_{view} \cdot M_{model} \cdot V_{local} $$</div>
					</section>
					<section>
						$$ V_{clip} = M_{projection} \cdot M_{view} \cdot M_{model} \cdot V_{local} $$
						<note style="text-align: left">Note that the order of matrix multiplication is reversed (remember that we need to read matrix multiplication from right to left).</note>
						<p class="fragment">The resulting vertex should then be assigned to <code>gl_Position</code> in the vertex shader and OpenGL will then automatically perform perspective division and clipping.</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Hands On!</h2>
					</section>
						<section>
						<p class="fragment">Now that we know how to transform 3D coordinates to 2D coordinates we can start showing our objects as real 3D objects instead of a lame 2D plane we've been showing so far.</p>
						<p class="fragment">To start drawing in 3D we'll first create a model matrix.</p>
						<p class="fragment">The model matrix consists of translations, scaling and/or rotations we'd like to apply to <i>transform</i> all object's vertices it to the global world space.</p>
						<p class="fragment">Let's transform our plane a bit by rotating it on the x-axis so it looks like it's laying on the floor.</p>
					</section>
					<section>
						<pre><code>glm::mat4 model(1.0f);
model = glm::rotate(model, glm::radians(-55.0f), glm::vec3(1.0, 0.0, 0.0));</code></pre>
						<p class="fragment">By multiplying the vertex coordinates with this model matrix we're transforming the vertex coordinates to world coordinates.</p>
						<p class="fragment">Our plane that is slightly on the floor thus represents the plane in the global world.</p>
					</section>
					<section>
						<p class="fragment">Next we need to create a view matrix. We want to move slightly backwards in the scene so the object becomes visible (when in world space we're located at the origin (0,0,0)). To move around the scene, think about the following:</p>
						<ul>
							<li class="fragment">To move a camera backwards, is the same as moving the entire scene forward.</li>
							<li class="fragment">That is exactly what a view matrix does, we move the entire scene around inversed to where we want the camera to move.</li>
						</ul>
					</section>
					<section>
						<p class="fragment">Because we want to move backwards and since OpenGL is a right-handed system we have to move in the positive z-axis.</p>
						<p class="fragment">We do this by translating the scene towards the negative z-axis. This gives the impression that we are moving backwards.</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Right Handed System</h2>
					</section>
					<section>
						<p class="fragment">By convention, OpenGL is a right-handed system. What this basically says is that the positive x-axis is to your right, the positive y-axis is up and the positive z-axis is backwards.</p>
						<p class="fragment">Think of your screen being the center of the 3 axes and the positive z-axis going through your screen towards you.</p>
						<div class="fragment"><img src="https://learnopengl.com/img/getting-started/coordinate_systems_right_handed.png" class="plain" width="30%"></div>
					</section>
					<section>
						<p class="fragment">To understand why it's called right-handed do the following:</p>
						<ol>
							<li class="fragment">Stretch your right-arm along the positive y-axis with your hand up top.</li>
							<li class="fragment">Let your thumb point to the right.</li>
							<li class="fragment">Let your pointing finger point up.</li>
							<li class="fragment">Now bend your middle finger downwards 90 degrees.</li>
						</ol>
						<p class="fragment">If you did things right, your thumb should point towards the positive x-axis, the pointing finger towards the positive y-axis and your middle finger towards the positive z-axis. </p>
					</section>
					<section>
						<p class="fragment">If you were to do this with your left-arm you would see the z-axis is reversed.</p>
						<p class="fragment">This is known as a left-handed system and is commonly used by <b>DirectX</b>.</p>
						<p class="fragment">Note that in normalized device coordinates <b>OpenGL</b> actually uses a left-handed system (the projection matrix switches the handedness).</p>
					</section>
					<section>
						<pre><code class="stretch">glm::mat4 model(1.0f);
model = glm::rotate(model, glm::radians(-55.0f), glm::vec3(1.0, 0.0, 0.0));

glm::mat4 view = glm::mat4(1.0f);
// note that we're translating the scene in the reverse direction of where we want to move
view = glm::translate(view, glm::vec3(0.0f, 0.0f, -3.0f));

glm::mat4 projection;
projection = glm::perspective(glm::radians(45.0f), screenWidth / screenHeight, 0.1f, 100.0f);</code></pre>
					</section>
					<section>
						<pre><code class="stretch">#version 330 core

in vec3 position;
in vec3 color;
in vec2 texCoord;

out vec3 Color;
out vec2 TexCoord;

uniform mat4 model;
uniform mat4 view;
uniform mat4 projection;

void main()
{
	Color = color;
	TexCoord = texCoord;
	gl_Position = projection * view * model * vec4(position, 1.0);
}</code></pre>
					</section>
					<section>
						<pre><code class="stretch">glm::mat4 model(1.0f);
model = glm::rotate(model, glm::radians(-55.0f), glm::vec3(1.0, 0.0, 0.0));

glm::mat4 view = glm::mat4(1.0f);
// note that we're translating the scene in the reverse direction of where we want to move
view = glm::translate(view, glm::vec3(0.0f, 0.0f, -3.0f));

glm::mat4 projection;
projection = glm::perspective(glm::radians(45.0f), screenWidth / screenHeight, 0.1f, 100.0f);

GLuint modelLocation = glGetUniformLocation(shaderProgram, "model");
glUniformMatrix4fv(modelLocation, 1, GL_FALSE, glm::value_ptr(model));

GLuint viewLocation = glGetUniformLocation(shaderProgram, "view");
glUniformMatrix4fv(viewLocation, 1, GL_FALSE, glm::value_ptr(view));

GLuint projectionLocation = glGetUniformLocation(shaderProgram, "projection");
glUniformMatrix4fv(projectionLocation, 1, GL_FALSE, glm::value_ptr(projection));</code></pre>
					</section>


					<section>
						<pre><code class="stretch">glm::mat4 model(1.0f);
model = glm::rotate(model, glm::radians(-55.0f), glm::vec3(1.0, 0.0, 0.0));

glm::mat4 view = glm::mat4(1.0f);
// note that we're translating the scene in the reverse direction of where we want to move
view = glm::translate(view, glm::vec3(0.0f, 0.0f, -3.0f));

glm::mat4 projection;
projection = glm::perspective(glm::radians(45.0f), screenWidth / screenHeight, 0.1f, 100.0f);

GLuint modelLocation = glGetUniformLocation(shaderProgram, "model");
glUniformMatrix4fv(modelLocation, 1, GL_FALSE, glm::value_ptr(model));

GLuint viewLocation = glGetUniformLocation(shaderProgram, "view");
glUniformMatrix4fv(viewLocation, 1, GL_FALSE, glm::value_ptr(view));

GLuint projectionLocation = glGetUniformLocation(shaderProgram, "projection");
glUniformMatrix4fv(projectionLocation, 1, GL_FALSE, glm::value_ptr(projection));</code></pre>
					</section>
					<section>
						<img src="images/OpenGL/projected_rectangle.png" class="plain" width="60%">
					</section>
				</section>
				<section>
					<section>
						<h2>Draw a Cube</h2>
					</section>
					<section>
						<p class="fragment">Let's take the adventurous route and extend our 2D plane to a 3D cube. To render a cube we need a total of 36 vertices: 6 faces * 2 triangles * 3 vertices each:</p>
						<pre class="fragment"><code>float vertices[] = {
    -0.5f, -0.5f, -0.5f,  0.0f, 0.0f,
     0.5f, -0.5f, -0.5f,  1.0f, 0.0f,
     0.5f,  0.5f, -0.5f,  1.0f, 1.0f,
     0.5f,  0.5f, -0.5f,  1.0f, 1.0f,
    -0.5f,  0.5f, -0.5f,  0.0f, 1.0f,
    -0.5f, -0.5f, -0.5f,  0.0f, 0.0f,

    -0.5f, -0.5f,  0.5f,  0.0f, 0.0f,
     0.5f, -0.5f,  0.5f,  1.0f, 0.0f,
     0.5f,  0.5f,  0.5f,  1.0f, 1.0f,
     0.5f,  0.5f,  0.5f,  1.0f, 1.0f,
    -0.5f,  0.5f,  0.5f,  0.0f, 1.0f,
    -0.5f, -0.5f,  0.5f,  0.0f, 0.0f,

    -0.5f,  0.5f,  0.5f,  1.0f, 0.0f,
    -0.5f,  0.5f, -0.5f,  1.0f, 1.0f,
    -0.5f, -0.5f, -0.5f,  0.0f, 1.0f,
    -0.5f, -0.5f, -0.5f,  0.0f, 1.0f,
    -0.5f, -0.5f,  0.5f,  0.0f, 0.0f,
    -0.5f,  0.5f,  0.5f,  1.0f, 0.0f,

     0.5f,  0.5f,  0.5f,  1.0f, 0.0f,
     0.5f,  0.5f, -0.5f,  1.0f, 1.0f,
     0.5f, -0.5f, -0.5f,  0.0f, 1.0f,
     0.5f, -0.5f, -0.5f,  0.0f, 1.0f,
     0.5f, -0.5f,  0.5f,  0.0f, 0.0f,
     0.5f,  0.5f,  0.5f,  1.0f, 0.0f,

    -0.5f, -0.5f, -0.5f,  0.0f, 1.0f,
     0.5f, -0.5f, -0.5f,  1.0f, 1.0f,
     0.5f, -0.5f,  0.5f,  1.0f, 0.0f,
     0.5f, -0.5f,  0.5f,  1.0f, 0.0f,
    -0.5f, -0.5f,  0.5f,  0.0f, 0.0f,
    -0.5f, -0.5f, -0.5f,  0.0f, 1.0f,

    -0.5f,  0.5f, -0.5f,  0.0f, 1.0f,
     0.5f,  0.5f, -0.5f,  1.0f, 1.0f,
     0.5f,  0.5f,  0.5f,  1.0f, 0.0f,
     0.5f,  0.5f,  0.5f,  1.0f, 0.0f,
    -0.5f,  0.5f,  0.5f,  0.0f, 0.0f,
    -0.5f,  0.5f, -0.5f,  0.0f, 1.0f
};</code></pre>
					</section>
					<section>
						<p class="fragment">Update attributes data:</p>
						<pre class="fragment"><code>GLint posAttrib = glGetAttribLocation(shaderProgram, "position");
glEnableVertexAttribArray(posAttrib);
glVertexAttribPointer(posAttrib, 3, GL_FLOAT, GL_FALSE, 5 * sizeof(float), (void*)0);

//GLint colorAttrib = glGetAttribLocation(shaderProgram, "color");
//glEnableVertexAttribArray(colorAttrib);
//glVertexAttribPointer(colorAttrib, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(3 * sizeof(float)));

GLint texCoordAttrib = glGetAttribLocation(shaderProgram, "texCoord");
glEnableVertexAttribArray(texCoordAttrib);
glVertexAttribPointer(texCoordAttrib, 2, GL_FLOAT, GL_FALSE, 5 * sizeof(float), (void*)(3 * sizeof(float)));</code></pre>
						<p class="fragment">Draw</p>
						<pre class="fragment"><code>glDrawArrays(GL_TRIANGLES, 0, 36);</code></pre>
					</section>
					<section>
						<img src="images/OpenGL/cube.png" class="plain">
					</section>
				</section>
				<section>
					<section>
						<h2>Rotate the Cube</h2>
					</section>
					<section>
						<pre><code>int now = SDL_GetTicks();
float time = (now - start) / 1000.0f;

model = glm::mat4(1.0f);
model = glm::rotate(model, time, glm::vec3(0.5f, 1.0f, 0.0f));
glUniformMatrix4fv(modelLocation, 1, GL_FALSE, glm::value_ptr(model));</code></pre>
					</section>
					<section>
						<img src="images/OpenGL/rotated_cube.png" class="plain">
					</section>
					<section>
						<p class="fragment">Some sides of the cubes are being drawn over other sides of the cube.</p>
						<p class="fragment">This happens because when OpenGL draws your cube triangle-by-triangle, it will overwrite its pixels even though something else might've been drawn there before.</p>
						<p class="fragment">Because of this, some triangles are drawn on top of each other while they're not supposed to overlap.</p>
						<p class="fragment">Luckily, OpenGL stores depth information in a buffer called the <b>z-buffer</b> that allows OpenGL to decide when to draw over a pixel and when not to.</p>
						<p class="fragment">Using the <b>z-buffer</b> we can configure OpenGL to do depth-testing.</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Z-buffer</h2>
					</section>
					<section>
						<p class="fragment">However, if we want to make sure OpenGL actually performs the depth testing we first need to tell OpenGL we want to enable depth testing; it is disabled by default.</p>					
						<p class="fragment">We can enable depth testing using <code>glEnable</code>.</p>
						<p class="fragment">The <code>glEnable</code> and <code>glDisable</code> functions allow us to enable/disable certain functionality in OpenGL.</p>
						<p class="fragment">That functionality is then enabled/disabled until another call is made to disable/enable it.</p>
						<p class="fragment">Right now we want to enable depth testing by enabling <code>GL_DEPTH_TEST</code>:</p>
						<pre class="fragment"><code>glEnable(GL_DEPTH_TEST);</code></pre>
					</section>
					<section>
						<p class="fragment">Since we're using a depth buffer we also want to clear the depth buffer before each render iteration (otherwise the depth information of the previous frame stays in the buffer).</p>
						<p class="fragment">Just like clearing the color buffer, we can clear the depth buffer by specifying the <code>DEPTH_BUFFER_BIT</code> bit in the <code>glClear</code> function:</p>
						<pre class="fragment"><code>glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</code></pre>
					</section>
					<section>
						<img src="images/OpenGL/depth_test.png" class="plain">
					</section>
				</section>
				<section>
					<section>
						<h2>More Cubes!</h2>
					</section>
					<section>
						<p class="fragment">Say we wanted to display 10 of our cubes on screen.</p>
						<p class="fragment">Each cube will look the same but will only differ in where it's located in the world with each a different rotation.</p>
						<p class="fragment">The graphical layout of the cube is already defined so we don't have to change our buffers or attribute arrays when rendering more objects.</p>
						<p class="fragment">The only thing we have to change for each object is its model matrix where we transform the cubes into the world.</p>
					</section>
					<section>
						<p class="fragment">First, let's define a translation vector for each cube that specifies its position in world space. We'll define 10 cube positions in a <code>glm::vec3</code> array:</p>
						<pre class="fragment"><code>glm::vec3 cubePositions[] = {
	glm::vec3(0.0f,  0.0f,  0.0f),
	glm::vec3(2.0f,  5.0f, -15.0f),
	glm::vec3(-1.5f, -2.2f, -2.5f),
	glm::vec3(-3.8f, -2.0f, -12.3f),
	glm::vec3(2.4f, -0.4f, -3.5f),
	glm::vec3(-1.7f,  3.0f, -7.5f),
	glm::vec3(1.3f, -2.0f, -2.5f),
	glm::vec3(1.5f,  2.0f, -2.5f),
	glm::vec3(1.5f,  0.2f, -1.5f),
	glm::vec3(-1.3f,  1.0f, -1.5f)
};</code></pre>					
					</section>
					<section>
						<p class="fragment">Now, within the game loop we want to call the <code>glDrawArrays</code> function 10 times, but this time send a different model matrix to the vertex shader each time before we render.</p>
						<p class="fragment">We will create a small loop within the game loop that renders our object 10 times with a different model matrix. Note that we also add a small rotation to each container.</p>
						<pre class="fragment"><code>for (unsigned int i = 0; i < 10; ++i)
{
	glm::mat4 model(1.0f);
	model = glm::translate(model, cubePositions[i]);
	float angle = 20.0f * i;
	model = glm::rotate(model, glm::radians(angle), glm::vec3(1.0f, 0.3f, 0.5f));
	glUniformMatrix4fv(modelLocation, 1, GL_FALSE, glm::value_ptr(model));

	glDrawArrays(GL_TRIANGLES, 0, 36);
}</code></pre>
					</section>
					<section>
						<img src="images/OpenGL/more_cubes.png" class="plain">
					</section>
				</section>

			</div>
		</div>

		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				width: 1280,
				height: 720,
				controls: true,
				progress: true,
				center: true,
				hash: true,
				transition: 'convex',
				math: {
					// mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
					config: 'TeX-AMS_HTML-full',
					TeX: {
						Macros: {
							R: '\\mathbb{R}',
							set: [ '\\left\\{#1 \\; ; \\; #2\\right\\}', 2 ]
						}
					}
				},
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },					
					{ src: 'plugin/highlight/highlight.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/math/math.js', async: true }
				]
			});
		</script>
	</body>
</html>